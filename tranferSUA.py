
"""
    T·∫°o file user_expanded.csv
"""
import pandas as pd

# T·∫°o DataFrame ch·ªâ c√≥ c·ªôt user_id
df = pd.DataFrame({'user_id': range(1, 1001)})

# Xu·∫•t ra file CSV
df.to_csv('user_expanded.csv', index=False, encoding='utf-8')

print(" File 'user_expanded.csv' ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")

"""
    T·∫°o file purchases_expanded.csv
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ƒê·∫∑t seed ƒë·ªÉ t√°i l·∫≠p k·∫øt qu·∫£ ng·∫´u nhi√™n
np.random.seed(42)

# S·ªë l∆∞·ª£ng ng∆∞·ªùi d√πng v√† s·∫£n ph·∫©m
n_users = 1000
n_products = 500  # b·∫°n c√≥ th·ªÉ ƒë·ªïi n·∫øu bi·∫øt ch√≠nh x√°c s·ªë l∆∞·ª£ng s·∫£n ph·∫©m
n_records = 5000  # t·ªïng s·ªë d√≤ng mua h√†ng

# Sinh ng·∫´u nhi√™n user_id v√† product_id
user_ids = np.random.randint(1, n_users + 1, size=n_records)
product_ids = [f"id_{i:08d}" for i in np.random.randint(1, n_products + 1, size=n_records)]

# Sinh ng·∫´u nhi√™n timestamp trong kho·∫£ng 2023‚Äì2025
start_date = datetime(2023, 1, 1)
end_date = datetime(2025, 12, 31)
random_seconds = np.random.randint(0, int((end_date - start_date).total_seconds()), size=n_records)
timestamps = [start_date + timedelta(seconds=int(s)) for s in random_seconds]

# T·∫°o DataFrame
df = pd.DataFrame({
    'user_id': user_ids,
    'product_id': product_ids,
    'timestamp': [t.strftime("%Y-%m-%d %H:%M:%S") for t in timestamps]
})

# Xu·∫•t ra file CSV
df.to_csv('purchases_expanded.csv', index=False, encoding='utf-8')

print("File 'purchases_expanded.csv' ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
print(df.head())
"""
    T·∫°o m·ªôt file product_images_expanded.csv
"""
import os
import pandas as pd

# C√°c th∆∞ m·ª•c g·ªëc c·∫ßn qu√©t
root_dirs = [
    r"F:\Python\Project Code\img\img\CLOTHING",
    r"F:\Python\Project Code\img\MEN",
    r"F:\Python\Project Code\img\WOMEN"
]

records = []

for root_dir in root_dirs:
    if not os.path.exists(root_dir):
        print(f"Root folder kh√¥ng t·ªìn t·∫°i, b·ªè qua: {root_dir}")
        continue
    # CH·ªà D√ôNG os.walk L√Ä ƒê·ª¶
    for dirpath, dirnames, filenames in os.walk(root_dir):
        for fname in filenames:
            if fname.lower().endswith((".jpg", ".jpeg", ".png")):
                product_id = os.path.basename(dirpath)
                image_path = os.path.join(dirpath, fname)
                records.append((product_id.strip(), image_path))
#M·ª•c ƒë√≠ch: thu th·∫≠p t·∫•t c·∫£ file ·∫£nh trong root_dirs v√† √°nh x·∫° product_id ‚Üí image_path.
#C√°ch ho·∫°t ƒë·ªông:
#- Tr∆∞·ªõc ti√™n ki·ªÉm tra root_dir c√≥ t·ªìn t·∫°i kh√¥ng; n·∫øu kh√¥ng th√¨ b·ªè qua v√† in c·∫£nh b√°o.
#- D√πng os.walk(root_dir) ƒë·ªÉ ƒë·ªá quy, duy·ªát m·ªçi th∆∞ m·ª•c con v√† file.
#- V·ªõi m·ªói file ·∫£nh (d·ª±a v√†o extension), l·∫•y product_id b·∫±ng basename(dirpath) ‚Äî t·ª©c t√™n th∆∞ m·ª•c ch·ª©a file ‚Äî v√† l∆∞u c·∫∑p (product_id, image_path).

#C√°ch gi·∫£i th√≠ch ng·∫Øn khi th·∫ßy h·ªèi: d√πng os.listdir nhi·ªÅu c·∫•p, d·ªÖ n·ªï khi th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i 
# ho·∫∑c c·∫•u tr√∫c th∆∞ m·ª•c kh√°c. os.walk linh ho·∫°t v√† an to√†n h∆°n cho c·∫•u tr√∫c kh√¥ng ƒë·ªìng nh·∫•t.

# üîπ T·∫°o DataFrame ch·ªâ c√≥ 2 c·ªôt ID s·∫£n ph·∫ßm v√† ƒë∆∞·ªùng ƒë·∫øn d·∫´n file ·∫£nh
df = pd.DataFrame(records, columns=["product_id", "image_path"])

# Xu·∫•t ra CSV
output_path = "product_images_expanded.csv"
df.to_csv(output_path, index=False, encoding="utf-8")
# L∆∞u d·ªØ li·ªáu ra file ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y

print(f"File '{output_path}' ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng ({len(df)} ·∫£nh).")
print(df.head()) 

#==> T·∫°o m·ªôt b·∫£ng (CSV) √°nh x·∫° product_id ‚Üí image_path ƒë·ªÉ d√πng cho c√°c b∆∞·ªõc sau: 
# n·ªëi (join) v·ªõi th√¥ng tin s·∫£n ph·∫©m, hu·∫•n luy·ªán retrieval/model, ho·∫∑c hi·ªÉn th·ªã ·∫£nh trong app.

"""
    H√†m t·∫°o m·ªôt file browsing_history_expanded.csv => c√°c s·∫£n ph·∫©m user ƒë√£ t·ª´ng xem qua
    M√¥ ph·ªèng l·ªãch s·ª≠ ng∆∞·ªùi d√πng xem s·∫£n ph·∫©m (view events). D√πng ƒë·ªÉ ph√¢n t√≠ch h√†nh vi, 
#x√¢y funnel (view ‚Üí add-to-cart ‚Üí purchase), hu·∫•n luy·ªán recommender systems.
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ƒê·∫∑t seed ƒë·ªÉ t√°i l·∫≠p k·∫øt qu·∫£
np.random.seed(42)
# M·ª•c ƒë√≠ch: ƒê·∫£m b·∫£o m·ªói l·∫ßn ch·∫°y code s·∫Ω cho K·∫æT QU·∫¢ GI·ªêNG NHAU 

# Th√¥ng s·ªë
n_users = 1000        # s·ªë l∆∞·ª£ng user
n_products = 500      # s·ªë l∆∞·ª£ng s·∫£n ph·∫©m
n_records = 10000     # t·ªïng s·ªë l∆∞·ª£t xem

# Sinh user_id / product_id ng·∫´u nhi√™n t·ª´ 1-1000/ 10000
user_ids = np.random.randint(1, n_users + 1, size=n_records)
product_ids = [f"id_{i:08d}" for i in np.random.randint(1, n_products + 1, size=n_records)]

# Sinh timestamp ng·∫´u nhi√™n trong kho·∫£ng 2023‚Äì2025
start_date =datetime(2023, 1, 1)
end_date = datetime(2025, 12, 31)
total_sec = int((end_date - start_date).total_seconds())
random_seconds = np.random.randint(0, total_sec + 1, size=n_records)
timestamps = [start_date + timedelta(seconds=int(s)) for s in random_seconds]


# T·∫°o DataFrame
df = pd.DataFrame({ # T·∫°o dictionary v·ªõi 3 key-value pairs, m·ªói value l√† m·ªôt list


    'user_id': user_ids,
    'product_id': product_ids,
    'timestamp': [t.strftime("%Y-%m-%d %H:%M:%S") for t in timestamps] # Chuy·ªÉn ƒë·ªïi datetime object th√†nh string theo ƒë·ªãnh d·∫°ng
})

# Xu·∫•t ra file CSV
df.to_csv('browsing_history_expanded.csv', index=False, encoding='utf-8')

print("File 'browsing_history_expanded.csv' ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
print(df.head())


#===================================================================
"""
    *************T·∫°o m·ªôt file products_expanded.csv
    Chuy·ªÉn JSON m√¥ t·∫£ s·∫£n ph·∫©m th√†nh table c√≥ product_id, description,
    c·ªông th√™m m·ªôt s·ªë thu·ªôc t√≠nh gi·∫£ l·∫≠p (category, price, rating, product_name) 
    ƒë·ªÉ d√πng cho testing, demo, ho·∫∑c training.
"""
import pandas as pd
import numpy as np
import json
import os
import re

# ===== 1. ƒê·ªçc file JSON =====
json_path = "./list_description_inshop.json"
if not os.path.exists(json_path):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file JSON: {json_path}")
# B·∫£o ƒë·∫£m file t·ªìn t·∫°i, n·∫øu kh√¥ng s·∫Ω d·ª´ng script s·ªõm v·ªõi l·ªói r√µ r√†ng.

# ===== 1. ƒê·ªçc file JSON ============================
try:
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
except FileNotFoundError:
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file JSON: {json_path}")
except json.JSONDecodeError as e:
    raise ValueError(f"JSON b·ªã l·ªói c·∫•u tr√∫c: {e}")
#M·ª•c ƒë√≠ch: b·∫Øt l·ªói ph·ªï bi·∫øn khi ƒë·ªçc JSON:
#- file kh√¥ng t·ªìn t·∫°i ‚Üí b√°o r√µ v√† d·ª´ng,
#- file t·ªìn t·∫°i nh∆∞ng JSON corrupt/invalid ‚Üí b√°o l·ªói c·∫•u tr√∫c (c√≥ th√¥ng tin exception).

#json.JSONDecodeError gi√∫p tr·∫£ l·ªói c√≥ th√¥ng tin (v√≠ d·ª• d√≤ng/c·ªôt b·ªã sai) ƒë·ªÉ d·ªÖ s

# Chuy·ªÉn JSON th√†nh DataFrame
records = []
for item in data:
    product_id = item.get("item")
    product_id = str(product_id).strip()  # chu·∫©n ho√°   
    desc = item.get("description", "")
    if isinstance(desc, list):
        description = " ".join([str(x).strip() for x in desc if str(x).strip()])
    elif isinstance(desc, dict):
        description = " ".join([str(v).strip() for v in desc.values() if str(v).strip()])
    else:
        description = str(desc).strip()
    records.append({"product_id": product_id, "description": description})

#M·ª•c ƒë√≠ch: ƒë·∫£m b·∫£o description lu√¥n l√† chu·ªói text h·ª£p l·ªá, b·∫•t k·ªÉ input l√† list, dict hay string.
#- N·∫øu l√† list: join c√°c ph·∫ßn t·ª≠ (th∆∞·ªùng l√† d√≤ng m√¥ t·∫£) b·∫±ng kho·∫£ng tr·∫Øng.
#- N·∫øu dict: join c√°c gi√° tr·ªã ‚Äî h·ªØu √≠ch n·∫øu JSON l∆∞u description d∆∞·ªõi d·∫°ng object (v√≠ d·ª• {"short": "...", "long": "..."}).
#- N·∫øu r·ªóng ho·∫∑c None ‚Üí tr·ªü th√†nh ""

#==> Em l√†m ch·ª©c nƒÉng ‚Äònormalize‚Äô ƒë·ªÉ m·ªçi description ƒë·ªÅu l√† string chu·∫©n, 
# gi√∫p downstream processing (category detect, tag extract) ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh.‚Äù

df = pd.DataFrame(records)

# ===== 2. ƒê·ªçc file attribute (list_attr_cloth.txt) =====
attr_path = "./list_attr_cloth.txt"
if not os.path.exists(attr_path):
    raise FileNotFoundError(f" Kh√¥ng t√¨m th·∫•y file: {attr_path}")

# ƒê·ªçc t·ª´ng d√≤ng (b·ªè d√≤ng tr·ªëng, b·ªè xu·ªëng d√≤ng)
# ===== 2. ƒê·ªçc file attribute (list_attr_cloth.txt) =====
try:
    with open(attr_path, "r", encoding="utf-8") as f:
        attributes = [line.strip().lower() for line in f if line.strip()]
except FileNotFoundError:
    raise FileNotFoundError(f" Kh√¥ng t√¨m th·∫•y file thu·ªôc t√≠nh: {attr_path}")
except UnicodeDecodeError:
    raise UnicodeError(f" L·ªói encoding khi ƒë·ªçc file thu·ªôc t√≠nh: {attr_path}")
# ki·ªÉm tra file attributes ƒë·ªÉ tr√°nh l·ªói encoding v√† ƒë·ªÉ pipeline bi·∫øt r√µ nguy√™n nh√¢n n·∫øu file kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.‚Äù
  
    ## ƒê·ªçc file ch·ª©a c√°c thu·ªôc t√≠nh qu·∫ßn √°o ƒë·ªÉ ph√¢n lo·∫°i.
    #==> M·ªói d√≤ng file list_attr_cloth.txt ƒë∆∞·ª£c strip v√† lower. 
    # D√πng ƒë·ªÉ sau n√†y match tags/thu·ªôc t√≠nh (v√≠ d·ª• color, material).

#lo·∫°i b·ªè d√≤ng tr·ªëng
# Th·∫ßy c√≥ th·ªÉ h·ªèi: "attributes d√πng ƒë·ªÉ l√†m g√¨?" 
#  tr·∫£ l·ªùi: c√≥ th·ªÉ d√πng ƒë·ªÉ t√¨m m√†u, ch·∫•t li·ªáu trong description b·∫±ng c√°ch
#  d√≤ t·ª´ng attribute trong text (v·ªõi regex \b{attr}\b) r·ªìi l∆∞u as tags.

print(f"ƒê√£ ƒë·ªçc {len(attributes)} d√≤ng thu·ªôc t√≠nh t·ª´ list_attr_cloth.txt")

# ===== 3. Danh s√°ch category ch√≠nh ==========================================
# (c√≥ th·ªÉ m·ªü r·ªông th√™m c√°c lo·∫°i l·∫•y t·ª´ attributes n·∫øu mu·ªën)
main_categories = [
    "dress", "blouse", "jacket", "skirt", "top", "tee", "jeans",
    "sweater", "pants", "shorts", "cardigan", "coat", "hoodie",
    "romper", "leggings", "vest", "jumpsuit", "shirt", "polo", "tank"
]

# =================== 4. X√°c ƒë·ªãnh category d·ª±a v√†o description ===========================
def detect_category(text):
    text = text.lower()
    for cat in main_categories:
        if re.search(rf"\b{cat}\b", text):
            return cat.capitalize()
    return "Other"

df["category"] = df["description"].apply(detect_category)

# ===== 5. Sinh d·ªØ li·ªáu gi·∫£ cho price, rating, product_name =====
np.random.seed(42)

df["price"] = np.round(np.random.uniform(5, 120, len(df)), 2)
df["rating"] = np.round(np.random.uniform(1.0, 5.0, len(df)), 1)

prefixes = ["Elegant", "Modern", "Classic", "Casual", "Trendy", "Vintage", "Sporty"]
items = ["Top", "Blouse", "Jacket", "Skirt", "Dress", "Tee", "Jeans", "Sweater"]

df["product_name"] = [
    f"{np.random.choice(prefixes)} {np.random.choice(items)}"
    for _ in range(len(df))
]

# ===== 6. Xu·∫•t ra file CSV =====
output_path = "products_expanded.csv"  
df.to_csv(output_path, index=False, encoding="utf-8")

print(f"\n ƒê√£ t·∫°o file '{output_path}' th√†nh c√¥ng ({len(df)} d√≤ng)!")
print(df.head(10))

# "T·∫°i sao d√πng index=False?"
# "ƒê·ªÉ tr√°nh t·∫°o c·ªôt index th·ª´a trong file CSV, gi·ªØ d·ªØ li·ªáu s·∫°ch s·∫Ω v√† ti·∫øt ki·ªám dung l∆∞·ª£ng."

#"utf-8-sig kh√°c utf-8 th·∫ø n√†o?"
#‚Üí "utf-8-sig th√™m BOM gi√∫p Excel t·ª± ƒë·ªông nh·∫≠n di·ªán encoding, trong khi utf-8 th√¥ng th∆∞·ªùng c√≥ th·ªÉ l√†m Excel hi·ªÉn th·ªã ti·∫øng Vi·ªát sai."

# "T·∫°i sao in head(10) thay v√¨ to√†n b·ªô DataFrame?"
#‚Üí "ƒê·ªÉ ki·ªÉm tra nhanh k·∫øt qu·∫£ m√† kh√¥ng l√†m tr√†n console v·ªõi qu√° nhi·ªÅu d·ªØ li·ªáu."

# "C√≥ c√°ch n√†o kh√°c ƒë·ªÉ xu·∫•t DataFrame kh√¥ng?"
#‚Üí "C√≥ ·∫°, ngo√†i CSV c√≤n c√≥ th·ªÉ xu·∫•t Excel (.xlsx) v·ªõi to_excel(), JSON v·ªõi to_json(), ho·∫∑c SQL database tr·ª±c ti·∫øp."




#  ====================T√ìM T·∫ÆT QUY TR√åNH T·ªîNG TH·ªÇ===========
# Kh·ªüi t·∫°o ‚Üí Thi·∫øt l·∫≠p seed v√† tham s·ªë
#ƒê·ªçc d·ªØ li·ªáu g·ªëc ‚Üí JSON, file text, duy·ªát th∆∞ m·ª•c ·∫£nh
#Ti·ªÅn x·ª≠ l√Ω ‚Üí Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng, l√†m s·∫°ch d·ªØ li·ªáu
#Sinh d·ªØ li·ªáu gi·∫£ ‚Üí Random values cho c√°c tr∆∞·ªùng c√≤n thi·∫øu
#T·∫°o c·∫•u tr√∫c ‚Üí Chuy·ªÉn th√†nh DataFrame c√≥ c·∫•u tr√∫c
#Xu·∫•t file ‚Üí Ghi ra CSV v·ªõi encoding ph√π h·ª£p